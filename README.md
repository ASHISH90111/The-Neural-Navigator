# The-Neural-Navigator
 Build a Neural Network that acts like a "Smart GPS". Your model must take two inputs: a 2D image (a map with colored shapes) and a text command (e.g., "Go to the Red Circle"), and output a sequence of (x, y) coordinates representing the path to the target.
ğŸ“Œ Problem Statement

Given:

A 128Ã—128 RGB image containing simple geometric shapes

A text instruction describing the target

Predict:

A sequence of 10 (x, y) coordinates forming a path from the center of the image to the target.

ğŸ“‚ Project Structure
assignment_solution/
â”‚
â”œâ”€â”€ data_loader.py        # Dataset & preprocessing
â”œâ”€â”€ model.py              # Vision + Text fusion model
â”œâ”€â”€ train.py              # Training loop with scheduler
â”œâ”€â”€ predict.py            # Inference & visualization
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ training_loss.png
â”‚   â”œâ”€â”€ pred_0.png ...
â””â”€â”€ README.md

ğŸ§  Model Architecture
1. Vision Encoder

A CNN extracts spatial features from the 128Ã—128 RGB image:

3 convolution blocks

Adaptive average pooling

Output flattened feature vector

2. Text Encoder

Learnable embedding for instruction tokens

Padding-aware embedding

Mean pooling over tokens

3. Fusion

The image and text features are concatenated and passed through a fully connected network.

4. Decoder

A regression head predicts 10 (x, y) coordinates representing the navigation path.

ğŸ— Architecture Diagram (Conceptual)
Image â”€â”€â–¶ CNN â”€â”€â”
                â”œâ”€â”€ Concatenate â”€â”€ FC Layers â”€â”€ Path (10Ã—2)
Text  â”€â”€â–¶ Embed â”˜

ğŸ§ª Training Details
Loss Function
Total Loss = MSE(path, ground_truth)
           + 0.1 Ã— Smoothness Loss


Smoothness loss penalizes abrupt direction changes:

(path[:, 1:] - path[:, :-1])Â²


This produces more realistic trajectories.

Optimizer & Scheduler

Optimizer: Adam

Learning Rate: 1e-3

Scheduler: StepLR (step=10, gamma=0.7)

ğŸ“‰ Training Behavior

Rapid initial convergence

Stable decreasing loss

Smooth convergence curve

No divergence or instability

A training-loss plot is saved automatically:

outputs/training_loss.png

ğŸ§  Inference

Run:

python predict.py


This:

Loads the trained model

Runs inference on test images

Draws predicted paths

Saves output images to outputs/

Example output:

âœ” Path points move toward the correct target
âœ” Smooth trajectory
âœ” Correct semantic grounding (color + shape)

âš ï¸ Challenges & Solutions
1. Model checkpoint incompatibility

Problem:
Changing network layers caused size mismatch errors when loading old checkpoints.

Solution:
Implemented a safe loading mechanism that loads only compatible weights and skips mismatched layers. This allowed training to resume without crashing.

2. Text padding caused index errors

Problem:
Text sequences had different lengths, causing embedding index errors.

Solution:
Added a padding token and updated embedding size accordingly. Padding index was ignored during learning.

3. Noisy / jagged predicted paths

Problem:
Initial predictions had sharp, unrealistic direction changes.

Solution:
Added a smoothness regularization term that penalizes large step-to-step changes.

4. Training instability during early epochs

Solution:
Used a learning-rate scheduler to stabilize convergence.

ğŸ“Š Accuracy / Performance

Training loss decreases smoothly and converges

Model consistently predicts paths toward correct targets

Visual outputs are coherent and interpretable

Demonstrates correct multimodal reasoning

The goal was not perfect geometric precision but stable reasoning and correct directional intent.

âœ… Key Features Implemented

âœ” Custom PyTorch Dataset
âœ” Vision encoder (CNN)
âœ” Text embedding encoder
âœ” Multi-modal fusion
âœ” Regression-based path prediction
âœ” Smoothness regularization
âœ” Learning rate scheduler
âœ” Resume-safe checkpoint loading
âœ” Prediction visualization
âœ” Clean modular code

ğŸ§¾ Requirements
torch
torchvision
numpy
opencv-python
matplotlib
tqdm
Pillow

ğŸš€ How to Run
Train
python train.py

Predict
python predict.py

ğŸ¯ Final Notes

This project demonstrates:

Multi-modal learning

Practical debugging skills

Model iteration & refinement

Stable training practices

Clean engineering structure

It aligns with real-world robotics ML workflows where perception, language, and control must be combined effectively.
